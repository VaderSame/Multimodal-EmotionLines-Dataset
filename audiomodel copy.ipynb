{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b541a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import yaml , os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5976e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "c:\\UWO\\Projects\\Multimodal Emotion detection\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained Whisper\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2abf6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./meld.yaml', 'r') as fp:\n",
    "    meld_dict = yaml.safe_load(fp)\n",
    "    \n",
    "train_split = meld_dict['train']\n",
    "test_split = meld_dict['test']\n",
    "dev_split = meld_dict['dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92b5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for aud_key in train_split.keys():\n",
    "    aud_path = os.path.normpath(os.path.join(\"./dataset_extracted/output_train_extracted\", f\"{aud_key}.wav\"))\n",
    "    \n",
    "    if not os.path.exists(aud_path):\n",
    "        print(f\"File not found, skipping: {aud_path}\")\n",
    "        continue\n",
    "\n",
    "    aud_properties = train_split[aud_key]\n",
    "    text = aud_properties['Utterance']\n",
    "    emotion_label = aud_properties['Emotion']\n",
    "    \n",
    "\n",
    "for aud_key in dev_split.keys():\n",
    "    aud_path = os.path.normpath(os.path.join(\"./dataset_extracted/output_dev_extracted\", f\"{aud_key}.wav\"))\n",
    "\n",
    "    if not os.path.exists(aud_path):\n",
    "        print(f\"File not found, skipping: {aud_path}\")\n",
    "        continue\n",
    "\n",
    "    aud_properties = dev_split[aud_key]\n",
    "    text = aud_properties['Utterance']\n",
    "    emotion_label = aud_properties['Emotion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6715ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract mean pooled encoder features from audio\n",
    "# import whisperx\n",
    "# whisper_model = whisperx.load_model(\"base\")\n",
    "# whisper_model.eval()\n",
    "# whisper_model = whisper_model.to(device)\n",
    "\n",
    "# def extract_whisper_features(audio_path):\n",
    "#     # audio = whisper.load_audio(audio_path)\n",
    "#     from pathlib import Path\n",
    "#     audio_path = Path(audio_path).as_posix()\n",
    "#     audio = whisperx.load_audio(audio_path)\n",
    "\n",
    "#     audio = whisperx.pad_or_trim(audio)\n",
    "#     mel = whisperx.log_mel_spectrogram(audio).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         features = whisper_model.encoder(mel.unsqueeze(0))  # shape: [1, frames, dim]\n",
    "#     return features.mean(dim=1).squeeze().cpu().numpy()  # shape: [dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c8b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io\n",
    "import torch\n",
    "from whisper.model import AudioEncoder\n",
    "from whisper import _MODELS, _ALIGNMENT_HEADS, _download, available_models\n",
    "from whisper import ModelDimensions\n",
    "from typing import Optional, Union\n",
    "\n",
    "def load_model(\n",
    "    model,\n",
    "    name: str,\n",
    "    device: Optional[Union[str, torch.device]] = None,\n",
    "    download_root: str = None,\n",
    "    in_memory: bool = False,\n",
    ") -> AudioEncoder:\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if download_root is None:\n",
    "        default = os.path.join(os.path.expanduser(\"~\"), \".cache\")\n",
    "        download_root = os.path.join(os.getenv(\"XDG_CACHE_HOME\", default), \"whisper\")\n",
    "\n",
    "    if name in _MODELS:\n",
    "        checkpoint_file = _download(_MODELS[name], download_root, in_memory)\n",
    "        alignment_heads = _ALIGNMENT_HEADS[name]\n",
    "    elif os.path.isfile(name):\n",
    "        checkpoint_file = open(name, \"rb\").read() if in_memory else name\n",
    "        alignment_heads = None\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Model {name} not found; available models = {available_models()}\"\n",
    "        )\n",
    "\n",
    "    with (\n",
    "        io.BytesIO(checkpoint_file) if in_memory else open(checkpoint_file, \"rb\")\n",
    "    ) as fp:\n",
    "        checkpoint = torch.load(fp, map_location=device)\n",
    "    del checkpoint_file\n",
    "\n",
    "    dims = ModelDimensions(**checkpoint[\"dims\"])\n",
    "    print(\n",
    "        dims.n_mels,\n",
    "        dims.n_audio_ctx,\n",
    "        dims.n_audio_state,\n",
    "        dims.n_audio_head,\n",
    "        dims.n_audio_layer,\n",
    "    )\n",
    "    # model = AudioEncoder(\n",
    "    #     dims.n_mels,\n",
    "    #     dims.n_audio_ctx,\n",
    "    #     dims.n_audio_state,\n",
    "    #     dims.n_audio_head,\n",
    "    #     dims.n_audio_layer,\n",
    "    # )\n",
    "\n",
    "    model_state_dict = model.state_dict()\n",
    "    print(\"\\n\".join([f for f in checkpoint[\"model_state_dict\"].keys() if \"encoder\" in f and f in model_state_dict.keys()]))\n",
    "    encoder_keys = [f for f in checkpoint[\"model_state_dict\"].keys() if \"encoder\" in f]\n",
    "    missing_keys, unexpected_keys = model.load_state_dict({f: checkpoint[\"model_state_dict\"][f] for f in encoder_keys}, \n",
    "                          strict=False)\n",
    "    # if alignment_heads is not None:\n",
    "    #     model.set_alignment_heads(alignment_heads)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8343dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Literal\n",
    "\n",
    "import librosa\n",
    "import whisper\n",
    "import torch\n",
    "import yaml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# whisper_model = whisper.load_model(\"base\")\n",
    "# whisper_model.eval()\n",
    "# whisper_model.to(torch.device(\"cuda\"))\n",
    "\n",
    "class WhisperMELDDataset(Dataset):\n",
    "    def __init__(self, dataset_path='./meld.yaml', split_name='train', sr=16000, label_encoder=None, \n",
    "                 mode: Literal[\"default\", \"temporal\", \"full\"]=\"default\", whisper_model=None):\n",
    "        super(WhisperMELDDataset, self).__init__()\n",
    "\n",
    "        with open(dataset_path, 'r') as fp:\n",
    "            meld_dict = yaml.safe_load(fp)\n",
    "        \n",
    "        self.split_name = split_name\n",
    "        self.sr = sr\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Extract correct split\n",
    "        if split_name == 'train':\n",
    "            self.split = meld_dict['train']\n",
    "            self.audio_dir = \"./dataset_extracted/output_train_extracted\"\n",
    "        elif split_name == 'test':\n",
    "            self.split = meld_dict['test']\n",
    "            self.audio_dir = \"./dataset_extracted/output_test_extracted\"\n",
    "        elif split_name == 'dev':\n",
    "            self.split = meld_dict['dev']\n",
    "            self.audio_dir = \"./dataset_extracted/output_dev_extracted\"\n",
    "        else:\n",
    "            raise ValueError(\"split_name must be one of: train, test, dev\")\n",
    "\n",
    "        self.whisper_model = whisper_model\n",
    "        self.keys = list(self.split.keys())\n",
    "\n",
    "        # Build label encoder if not provided\n",
    "        if label_encoder is None:\n",
    "            all_labels = [entry['Emotion'] for entry in self.split.values()]\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            self.label_encoder.fit(all_labels)\n",
    "        else:\n",
    "            self.label_encoder = label_encoder\n",
    "\n",
    "        # Pre-encode all labels\n",
    "        self.encoded_labels = {\n",
    "            k: self.label_encoder.transform([v['Emotion']])[0]\n",
    "            for k, v in self.split.items()\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def extract_whisper_features(self, audio_path):\n",
    "        # audio = whisper.load_audio(audio_path)\n",
    "        # audio_path = Path(audio_path).as_posix()\n",
    "        # print(audio_path, isfile(audio_path))\n",
    "        try:\n",
    "            audio, _ = librosa.load(audio_path, sr=self.sr)\n",
    "            # audio = whisper.load_audio(join(os.getcwd(), audio_path))\n",
    "            audio = whisper.pad_or_trim(audio)    \n",
    "            mel = whisper.log_mel_spectrogram(audio).to(device)\n",
    "            \n",
    "            if self.mode!=\"full\":\n",
    "                with torch.no_grad():\n",
    "                    features = self.whisper_model.encoder(mel.unsqueeze(0))  # [1, T, 768]\n",
    "                    # print(features.shape)\n",
    "            else:\n",
    "                feat = torch.zeros(1024).to(device)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Failed to load audio {audio_path}: {e} | Exists:{isfile(audio_path)}\")\n",
    "            feat = torch.zeros(1024).to(device)\n",
    "            \n",
    "        if self.mode==\"default\":\n",
    "            mn = features.mean(dim=1).squeeze()\n",
    "            std = features.std(dim=1).squeeze()\n",
    "            feat = torch.concatenate([mn, std], dim=0)\n",
    "            return feat\n",
    "        elif self.mode==\"temporal\":\n",
    "            feat = features.detach()\n",
    "            return feat\n",
    "        elif self.mode==\"full\":\n",
    "            return mel\n",
    "        return feat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aud_key = self.keys[idx]\n",
    "        # audio_path = os.path.join(self.audio_dir, f\"{aud_key}.wav\")\n",
    "        # audio_path = os.path.normpath(os.path.join(self.audio_dir, f\"{aud_key}.wav\"))\n",
    "        # audio_path = Path(audio_path).as_posix()\n",
    "        audio_path = os.path.join(self.audio_dir, f\"{aud_key}.wav\")\n",
    "        features = self.extract_whisper_features(audio_path)\n",
    "        \n",
    "        label = self.encoded_labels[aud_key]\n",
    "        return features, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ed4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare label encoder manually using meld.yaml (for reproducibility)\n",
    "import yaml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "with open('C:/UWO/Projects/Multimodal Emotion detection/meld.yaml', 'r') as fp:\n",
    "    meld_dict = yaml.safe_load(fp)\n",
    "\n",
    "# Use the train split to fit the encoder\n",
    "all_labels = [entry['Emotion'] for entry in meld_dict['train'].values()]\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Step 2: Instantiate datasets\n",
    "# train_dataset = WhisperMELDDataset(dataset_path='C:/UWO/Projects/Multimodal Emotion detection/meld.yaml', split_name='train', label_encoder=label_encoder)\n",
    "# dev_dataset   = WhisperMELDDataset(dataset_path='C:/UWO/Projects/Multimodal Emotion detection/meld.yaml', split_name='dev',   label_encoder=label_encoder)\n",
    "# test_dataset  = WhisperMELDDataset(dataset_path='C:/UWO/Projects/Multimodal Emotion detection/meld.yaml', split_name='test',  label_encoder=label_encoder)\n",
    "# train_dataset = WhisperMELDDataset(dataset_path='C:/UWO/Projects/Multimodal Emotion detection/meld.yaml', split_name='train', label_encoder=label_encoder, mode=\"temporal\")\n",
    "# dev_dataset   = WhisperMELDDataset(dataset_path='C:/UWO/Projects/Multimodal Emotion detection/meld.yaml', split_name='dev',   label_encoder=label_encoder, mode=\"temporal\")\n",
    "# test_dataset  = WhisperMELDDataset(dataset_path='C:/UWO/Projects/Multimodal Emotion detection/meld.yaml', split_name='test',  label_encoder=label_encoder, mode=\"temporal\")\n",
    "train_dataset = WhisperMELDDataset(dataset_path='C:/UWO/Projects/Multimodal Emotion detection/meld.yaml', split_name='train', label_encoder=label_encoder, mode=\"full\")\n",
    "dev_dataset   = WhisperMELDDataset(dataset_path='C:/UWO/Projects/Multimodal Emotion detection/meld.yaml', split_name='dev',   label_encoder=label_encoder, mode=\"full\")\n",
    "test_dataset  = WhisperMELDDataset(dataset_path='C:/UWO/Projects/Multimodal Emotion detection/meld.yaml', split_name='test',  label_encoder=label_encoder, mode=\"full\")\n",
    "\n",
    "# Step 3: Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "dev_loader   = DataLoader(dev_dataset, batch_size=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d21ee08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fd4488f23b401cb5f57c103436f048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found batch with features shape: torch.Size([4, 80, 3000]), labels shape: torch.Size([4])\n",
      "torch.Size([9988])\n"
     ]
    }
   ],
   "source": [
    "label_arr = []\n",
    "for i, (features, label) in enumerate(tqdm(train_loader)):\n",
    "    label_arr.append(label.cpu())\n",
    "    if i == 0:  # Just print the first batch\n",
    "        print(f\"Found batch with features shape: {features.shape}, labels shape: {label.shape}\")\n",
    "    # break\n",
    "label_arr = torch.concatenate(label_arr, dim=0).to(device)\n",
    "print(label_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a817ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample paths from training set:\n",
      "Train path 1: ./dataset_extracted/output_train_extracted\\dia0_utt0.wav\n",
      "File exists: True\n",
      "Train path 2: ./dataset_extracted/output_train_extracted\\dia0_utt1.wav\n",
      "File exists: True\n",
      "Train path 3: ./dataset_extracted/output_train_extracted\\dia0_utt10.wav\n",
      "File exists: True\n",
      "Train path 4: ./dataset_extracted/output_train_extracted\\dia0_utt11.wav\n",
      "File exists: True\n",
      "Train path 5: ./dataset_extracted/output_train_extracted\\dia0_utt12.wav\n",
      "File exists: True\n",
      "\n",
      "Sample paths from validation set:\n",
      "Dev path 1: ./dataset_extracted/output_dev_extracted\\dia0_utt0.wav\n",
      "File exists: True\n",
      "Dev path 2: ./dataset_extracted/output_dev_extracted\\dia0_utt1.wav\n",
      "File exists: True\n",
      "Dev path 3: ./dataset_extracted/output_dev_extracted\\dia100_utt0.wav\n",
      "File exists: True\n",
      "Dev path 4: ./dataset_extracted/output_dev_extracted\\dia101_utt0.wav\n",
      "File exists: True\n",
      "Dev path 5: ./dataset_extracted/output_dev_extracted\\dia102_utt0.wav\n",
      "File exists: True\n",
      "\n",
      "Sample paths from test set:\n",
      "Test path 1: ./dataset_extracted/output_test_extracted\\dia0_utt0.wav\n",
      "File exists: True\n",
      "Test path 2: ./dataset_extracted/output_test_extracted\\dia0_utt1.wav\n",
      "File exists: True\n",
      "Test path 3: ./dataset_extracted/output_test_extracted\\dia0_utt2.wav\n",
      "File exists: True\n",
      "Test path 4: ./dataset_extracted/output_test_extracted\\dia100_utt0.wav\n",
      "File exists: True\n",
      "Test path 5: ./dataset_extracted/output_test_extracted\\dia100_utt1.wav\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample paths from training set:\")\n",
    "for i, key in enumerate(train_dataset.keys[:5]):  # Print first 5 paths\n",
    "    audio_path = os.path.join(train_dataset.audio_dir, f\"{key}.wav\")\n",
    "    print(f\"Train path {i+1}: {audio_path}\")\n",
    "    print(f\"File exists: {os.path.exists(audio_path)}\")\n",
    "\n",
    "print(\"\\nSample paths from validation set:\")\n",
    "for i, key in enumerate(dev_dataset.keys[:5]):  # Print first 5 paths\n",
    "    audio_path = os.path.join(dev_dataset.audio_dir, f\"{key}.wav\")\n",
    "    print(f\"Dev path {i+1}: {audio_path}\")\n",
    "    print(f\"File exists: {os.path.exists(audio_path)}\")\n",
    "\n",
    "print(\"\\nSample paths from test set:\")\n",
    "for i, key in enumerate(test_dataset.keys[:5]):  # Print first 5 paths\n",
    "    audio_path = os.path.join(test_dataset.audio_dir, f\"{key}.wav\")\n",
    "    print(f\"Test path {i+1}: {audio_path}\")\n",
    "    print(f\"File exists: {os.path.exists(audio_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6707ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.286616  5.2651553 5.324094  0.8186214 0.3030064 2.0891027 1.1841139]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# label_arr = (label_arr.shape[0] - torch.sum(label_arr, dim=1))/label_arr.shape[0]\n",
    "label_weights = compute_class_weight(class_weight=\"balanced\", classes=np.arange(7), y=label_arr.cpu().numpy())\n",
    "label_weights = label_weights.astype(np.float32)\n",
    "print(label_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa957cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 1500 512 8 6\n",
      "encoder.positional_embedding\n",
      "encoder.conv1.weight\n",
      "encoder.conv1.bias\n",
      "encoder.conv2.weight\n",
      "encoder.conv2.bias\n",
      "encoder.blocks.0.mlp_ln.weight\n",
      "encoder.blocks.0.mlp_ln.bias\n",
      "encoder.blocks.0.mlp.0.weight\n",
      "encoder.blocks.0.mlp.0.bias\n",
      "encoder.blocks.0.mlp.2.weight\n",
      "encoder.blocks.0.mlp.2.bias\n",
      "encoder.blocks.0.attn_ln.weight\n",
      "encoder.blocks.0.attn_ln.bias\n",
      "encoder.blocks.0.attn.query.weight\n",
      "encoder.blocks.0.attn.query.bias\n",
      "encoder.blocks.0.attn.key.weight\n",
      "encoder.blocks.0.attn.value.weight\n",
      "encoder.blocks.0.attn.value.bias\n",
      "encoder.blocks.0.attn.out.weight\n",
      "encoder.blocks.0.attn.out.bias\n",
      "encoder.blocks.1.mlp_ln.weight\n",
      "encoder.blocks.1.mlp_ln.bias\n",
      "encoder.blocks.1.mlp.0.weight\n",
      "encoder.blocks.1.mlp.0.bias\n",
      "encoder.blocks.1.mlp.2.weight\n",
      "encoder.blocks.1.mlp.2.bias\n",
      "encoder.blocks.1.attn_ln.weight\n",
      "encoder.blocks.1.attn_ln.bias\n",
      "encoder.blocks.1.attn.query.weight\n",
      "encoder.blocks.1.attn.query.bias\n",
      "encoder.blocks.1.attn.key.weight\n",
      "encoder.blocks.1.attn.value.weight\n",
      "encoder.blocks.1.attn.value.bias\n",
      "encoder.blocks.1.attn.out.weight\n",
      "encoder.blocks.1.attn.out.bias\n",
      "encoder.blocks.2.mlp_ln.weight\n",
      "encoder.blocks.2.mlp_ln.bias\n",
      "encoder.blocks.2.mlp.0.weight\n",
      "encoder.blocks.2.mlp.0.bias\n",
      "encoder.blocks.2.mlp.2.weight\n",
      "encoder.blocks.2.mlp.2.bias\n",
      "encoder.blocks.2.attn_ln.weight\n",
      "encoder.blocks.2.attn_ln.bias\n",
      "encoder.blocks.2.attn.query.weight\n",
      "encoder.blocks.2.attn.query.bias\n",
      "encoder.blocks.2.attn.key.weight\n",
      "encoder.blocks.2.attn.value.weight\n",
      "encoder.blocks.2.attn.value.bias\n",
      "encoder.blocks.2.attn.out.weight\n",
      "encoder.blocks.2.attn.out.bias\n",
      "encoder.blocks.3.mlp_ln.weight\n",
      "encoder.blocks.3.mlp_ln.bias\n",
      "encoder.blocks.3.mlp.0.weight\n",
      "encoder.blocks.3.mlp.0.bias\n",
      "encoder.blocks.3.mlp.2.weight\n",
      "encoder.blocks.3.mlp.2.bias\n",
      "encoder.blocks.3.attn_ln.weight\n",
      "encoder.blocks.3.attn_ln.bias\n",
      "encoder.blocks.3.attn.query.weight\n",
      "encoder.blocks.3.attn.query.bias\n",
      "encoder.blocks.3.attn.key.weight\n",
      "encoder.blocks.3.attn.value.weight\n",
      "encoder.blocks.3.attn.value.bias\n",
      "encoder.blocks.3.attn.out.weight\n",
      "encoder.blocks.3.attn.out.bias\n",
      "encoder.blocks.4.mlp_ln.weight\n",
      "encoder.blocks.4.mlp_ln.bias\n",
      "encoder.blocks.4.mlp.0.weight\n",
      "encoder.blocks.4.mlp.0.bias\n",
      "encoder.blocks.4.mlp.2.weight\n",
      "encoder.blocks.4.mlp.2.bias\n",
      "encoder.blocks.4.attn_ln.weight\n",
      "encoder.blocks.4.attn_ln.bias\n",
      "encoder.blocks.4.attn.query.weight\n",
      "encoder.blocks.4.attn.query.bias\n",
      "encoder.blocks.4.attn.key.weight\n",
      "encoder.blocks.4.attn.value.weight\n",
      "encoder.blocks.4.attn.value.bias\n",
      "encoder.blocks.4.attn.out.weight\n",
      "encoder.blocks.4.attn.out.bias\n",
      "encoder.blocks.5.mlp_ln.weight\n",
      "encoder.blocks.5.mlp_ln.bias\n",
      "encoder.blocks.5.mlp.0.weight\n",
      "encoder.blocks.5.mlp.0.bias\n",
      "encoder.blocks.5.mlp.2.weight\n",
      "encoder.blocks.5.mlp.2.bias\n",
      "encoder.blocks.5.attn_ln.weight\n",
      "encoder.blocks.5.attn_ln.bias\n",
      "encoder.blocks.5.attn.query.weight\n",
      "encoder.blocks.5.attn.query.bias\n",
      "encoder.blocks.5.attn.key.weight\n",
      "encoder.blocks.5.attn.value.weight\n",
      "encoder.blocks.5.attn.value.bias\n",
      "encoder.blocks.5.attn.out.weight\n",
      "encoder.blocks.5.attn.out.bias\n",
      "encoder.ln_post.weight\n",
      "encoder.ln_post.bias\n",
      "WhisperClassifier(\n",
      "  (encoder): AudioEncoder(\n",
      "    (conv1): Conv1d(80, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (blocks): ModuleList(\n",
      "      (0-5): 6 x ResidualAttentionBlock(\n",
      "        (attn): MultiHeadAttention(\n",
      "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_post): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ELU(alpha=1.0)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ELU(alpha=1.0)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ELU(alpha=1.0)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=380928, out_features=256, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semal\\AppData\\Local\\Temp\\ipykernel_31448\\3321746527.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22e1fec0d6b452db4e2df975bc6dce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 2.0142 | [1e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8420cc9173e449194905e0f94caec36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.00      0.00      0.00        40\n",
      "         joy       0.15      0.67      0.25       163\n",
      "     neutral       0.00      0.00      0.00       469\n",
      "     sadness       0.00      0.00      0.00       111\n",
      "    surprise       0.19      0.47      0.27       150\n",
      "\n",
      "    accuracy                           0.16      1108\n",
      "   macro avg       0.05      0.16      0.07      1108\n",
      "weighted avg       0.05      0.16      0.07      1108\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedf934ed69a471f829e1afd04114d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training Loss: 1.9509 | [8.888888888888888e-06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac002ad009ff4fc8b4e02f79260ce8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.00      0.00      0.00        40\n",
      "         joy       0.16      0.39      0.23       163\n",
      "     neutral       0.52      0.08      0.13       469\n",
      "     sadness       0.00      0.00      0.00       111\n",
      "    surprise       0.18      0.79      0.30       150\n",
      "\n",
      "    accuracy                           0.20      1108\n",
      "   macro avg       0.12      0.18      0.09      1108\n",
      "weighted avg       0.27      0.20      0.13      1108\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51aa0d452d94216a3ce53aeae54d26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training Loss: 1.9121 | [7.77777777777778e-06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901067d5dc5848d98005cdd622e76a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.00      0.00      0.00        40\n",
      "         joy       0.16      0.48      0.24       163\n",
      "     neutral       0.55      0.61      0.58       469\n",
      "     sadness       0.00      0.00      0.00       111\n",
      "    surprise       0.33      0.23      0.27       150\n",
      "\n",
      "    accuracy                           0.36      1108\n",
      "   macro avg       0.15      0.19      0.16      1108\n",
      "weighted avg       0.30      0.36      0.32      1108\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8f7a40b09142c4ad0186c98a3b7940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Training Loss: 1.8726 | [6.666666666666667e-06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a45672ad10f43879303adc1fd936d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.23      0.52      0.32       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.00      0.00      0.00        40\n",
      "         joy       0.15      0.06      0.09       163\n",
      "     neutral       0.56      0.55      0.55       469\n",
      "     sadness       0.00      0.00      0.00       111\n",
      "    surprise       0.26      0.41      0.32       150\n",
      "\n",
      "    accuracy                           0.37      1108\n",
      "   macro avg       0.17      0.22      0.18      1108\n",
      "weighted avg       0.33      0.37      0.33      1108\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4652beac5ab84effad8c086970fc04fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Training Loss: 1.8487 | [5.555555555555557e-06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2424d6d1d9c4439ba447a25d5388780d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.31      0.56      0.40       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.00      0.00      0.00        40\n",
      "         joy       0.00      0.00      0.00       163\n",
      "     neutral       0.51      0.78      0.62       469\n",
      "     sadness       0.40      0.02      0.03       111\n",
      "    surprise       0.36      0.27      0.31       150\n",
      "\n",
      "    accuracy                           0.45      1108\n",
      "   macro avg       0.23      0.23      0.19      1108\n",
      "weighted avg       0.35      0.45      0.36      1108\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b180a3e7f1b4ae9b934a806401d2f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Training Loss: 1.8123 | [4.444444444444444e-06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f74046d52f4536874b48f46919ce3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.32      0.44      0.37       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.00      0.00      0.00        40\n",
      "         joy       0.18      0.42      0.25       163\n",
      "     neutral       0.56      0.42      0.48       469\n",
      "     sadness       0.39      0.08      0.13       111\n",
      "    surprise       0.33      0.31      0.32       150\n",
      "\n",
      "    accuracy                           0.35      1108\n",
      "   macro avg       0.26      0.24      0.22      1108\n",
      "weighted avg       0.39      0.35      0.35      1108\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb48b71ba0c4bc98d48d83bc62378eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Training Loss: 1.7639 | [3.3333333333333333e-06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac01ec4498174438ae8e20d4ce8fcff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.33      0.42      0.37       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.00      0.00      0.00        40\n",
      "         joy       0.17      0.28      0.22       163\n",
      "     neutral       0.52      0.52      0.52       469\n",
      "     sadness       0.62      0.09      0.16       111\n",
      "    surprise       0.30      0.31      0.31       150\n",
      "\n",
      "    accuracy                           0.37      1108\n",
      "   macro avg       0.28      0.23      0.22      1108\n",
      "weighted avg       0.39      0.37      0.36      1108\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27695352dca44779a2ec31cbcb418aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Training Loss: 1.7269 | [2.222222222222222e-06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3fee00cab54d6e8a2935ee81f8000d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.33      0.40      0.36       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.00      0.00      0.00        40\n",
      "         joy       0.17      0.09      0.12       163\n",
      "     neutral       0.53      0.58      0.56       469\n",
      "     sadness       0.23      0.27      0.25       111\n",
      "    surprise       0.31      0.37      0.34       150\n",
      "\n",
      "    accuracy                           0.39      1108\n",
      "   macro avg       0.22      0.25      0.23      1108\n",
      "weighted avg       0.36      0.39      0.37      1108\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5599fc3146345cab6b9830c26288452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Training Loss: 1.6791 | [1.111111111111111e-06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd396239ad644309b7f390795ef4c2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.34      0.48      0.40       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.00      0.00      0.00        40\n",
      "         joy       0.19      0.32      0.24       163\n",
      "     neutral       0.54      0.47      0.50       469\n",
      "     sadness       0.27      0.23      0.25       111\n",
      "    surprise       0.33      0.27      0.30       150\n",
      "\n",
      "    accuracy                           0.37      1108\n",
      "   macro avg       0.24      0.25      0.24      1108\n",
      "weighted avg       0.38      0.37      0.37      1108\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8d2fbbe2054563b7af5381e48f95d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 119\u001b[0m\n\u001b[0;32m    116\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./checkpoints/epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-acc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Final evaluation on test set\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----- Final Test Performance -----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 107\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, dev_loader, epochs)\u001b[0m\n\u001b[0;32m    104\u001b[0m output \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[0;32m    106\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[1;32m--> 107\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m    109\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\semal\\anaconda3\\envs\\gpu_conda\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MLP Classifier\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "total_epochs = 10\n",
    "\n",
    "class WhisperClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=768, hidden_dim=256, num_classes=7, train_whisper = False):\n",
    "        super(WhisperClassifier, self).__init__()\n",
    "\n",
    "        self.train_whisper = train_whisper\n",
    "        if train_whisper:\n",
    "            # self.audio_encoder = load_model(\"base\")\n",
    "            self.encoder = AudioEncoder(80, 1500, 512, 8, 6)\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self._to_linear = 128 * 93 * (input_dim//16)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self._to_linear, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        if self.train_whisper:\n",
    "            x = self.encoder(x)\n",
    "        # print(x.shape)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv_layers(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), self._to_linear)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Instantiate model\n",
    "model = WhisperClassifier(input_dim=512, hidden_dim=256, num_classes=7, train_whisper=True).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(label_weights).to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=1e-4, \n",
    "                             weight_decay=1e-5\n",
    "                             )\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "model = load_model(model, \"base\")\n",
    "print(model)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, \n",
    "                                            num_warmup_steps=int(0.1 * total_epochs * len(train_loader)), \n",
    "                                            num_training_steps=int(total_epochs * len(train_loader)))\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # X = normalize_x(X)\n",
    "            # X = transform_x(X)\n",
    "            \n",
    "            logits = model(X)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n",
    "    wf1 = multiclass_f1_score(torch.from_numpy(np.array(all_preds, dtype=np.int64)), \n",
    "                              torch.from_numpy(np.array(all_labels, dtype=np.int64)), \n",
    "                              num_classes=7, average=\"weighted\")\n",
    "    return wf1\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, dev_loader, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader):\n",
    "            X, y = batch\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # X = normalize_x(X)\n",
    "            # X = transform_x(X)\n",
    "            \n",
    "            y = y.type(torch.long)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            \n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            # break\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {total_loss/len(train_loader):.4f} | {scheduler.get_last_lr()}\")\n",
    "        acc = evaluate_model(model, dev_loader)\n",
    "        acc = str(acc).replace('.', '_')\n",
    "        torch.save(model.state_dict(), f\"./checkpoints/epoch_{epoch}-acc_{acc}.pth\")\n",
    "        # break\n",
    "\n",
    "train_model(model, train_loader, dev_loader, epochs=total_epochs)\n",
    "\n",
    "# Final evaluation on test set\n",
    "print(\"----- Final Test Performance -----\")\n",
    "evaluate_model(model, test_loader) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151fd2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
